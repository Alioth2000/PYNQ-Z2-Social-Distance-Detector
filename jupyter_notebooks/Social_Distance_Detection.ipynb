{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pynq/pl_server/device.py:594: UserWarning: Users will not get PARAMETERS / REGISTERS information through TCL files. HWH file is recommended.\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# 加载bit文件并初始化加速器\n",
    "from yolo import *\n",
    "base = Overlay(\"YOLO_HDMI.bit\")\n",
    "ALL_Init()\n",
    "\n",
    "# 初始化HDMI输出\n",
    "from pynq.lib.video import *\n",
    "\n",
    "Mode = VideoMode(640,480,24)\n",
    "hdmi_out = base.video.hdmi_out\n",
    "hdmi_out.configure(Mode,PIXEL_BGR)\n",
    "hdmi_out.start()\n",
    "outframe = hdmi_out.newframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import camera_configs  # 摄像头的标定数据\n",
    "from PIL import Image\n",
    "import threading, queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化摄像头\n",
    "cam = cv2.VideoCapture(0)  # 摄像头的ID不同设备上可能不同\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)  # 设置双目的宽度\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # 设置双目的高度\n",
    "\n",
    "que = queue.Queue(maxsize=3)\n",
    "\n",
    "# 拍摄程序\n",
    "def video_cap():\n",
    "    while(1):\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"camera is not connected!\")\n",
    "            break\n",
    "        que.put(frame)\n",
    "        if que.qsize()>1:\n",
    "            que.get()\n",
    "        # cv2.imwrite(ORIG_IMG_PATH, frame)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 新建一个线程运行拍摄程序\n",
    "t = threading.Thread(target=video_cap)\n",
    "t.start()\n",
    "\n",
    "\n",
    "# 主程序\n",
    "while(1):\n",
    "    # start_time = time.time()\n",
    "    frame = que.get()\n",
    "    # 分割左右图像\n",
    "    frame1 = frame[0:480, 0:640]\n",
    "    frame2 = frame[0:480, 640:1280]\n",
    "    \n",
    "    # 深度计算\n",
    "    img1_rectified = cv2.remap(frame1, camera_configs.left_map1, camera_configs.left_map2, cv2.INTER_LINEAR,\n",
    "                               cv2.BORDER_CONSTANT)\n",
    "    img2_rectified = cv2.remap(frame2, camera_configs.right_map1, camera_configs.right_map2, cv2.INTER_LINEAR,\n",
    "                               cv2.BORDER_CONSTANT)\n",
    "    imgL = cv2.cvtColor(img1_rectified, cv2.COLOR_BGR2GRAY)\n",
    "    imgR = cv2.cvtColor(img2_rectified, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    num = 0\n",
    "    SpeckleWindowSize = 1\n",
    "    SpeckleRange = 118\n",
    "    blockSize = 51\n",
    "    UniquenessRatio = 1\n",
    "    TextureThreshold = 91\n",
    "    MinDisparity = 1\n",
    "    PreFilterCap = 1\n",
    "    MaxDiff = 73\n",
    "\n",
    "    # 由BM算法生成深度图的矩阵\n",
    "    stereo = cv2.StereoBM_create(numDisparities=16 * num, blockSize=blockSize,)\n",
    "    stereo.setROI1(camera_configs.validPixROI1)\n",
    "    stereo.setROI2(camera_configs.validPixROI2)\n",
    "    stereo.setPreFilterCap(PreFilterCap)\n",
    "    stereo.setMinDisparity(MinDisparity)\n",
    "    stereo.setTextureThreshold(TextureThreshold)\n",
    "    stereo.setUniquenessRatio(UniquenessRatio)\n",
    "    stereo.setSpeckleWindowSize(SpeckleWindowSize)\n",
    "    stereo.setSpeckleRange(SpeckleRange)\n",
    "    stereo.setDisp12MaxDiff(MaxDiff)\n",
    "\n",
    "    disparity = stereo.compute(imgL, imgR)\n",
    "    disp = cv2.normalize(disparity, disparity, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    threeD = cv2.reprojectImageTo3D(disparity.astype(np.float32) / 16., camera_configs.Q)\n",
    "    \n",
    "    # 利用YOLO神经网络检测人物，同时判断人与人之间距离\n",
    "    frame_in = Image.fromarray(frame1.astype('uint8')).convert('RGB')\n",
    "    img_w =frame_in.size[0]\n",
    "    img_h =frame_in.size[1]\n",
    "    img_out = frame_in\n",
    "    YOLO_Detect(frame_in,img_w,img_h,img_out,threeD)\n",
    "    img_hdmi = np.array(img_out)\n",
    "    \n",
    "    # display(img_out)\n",
    "    # clear_output()\n",
    "    # end_time = time.time()\n",
    "    # print(end_time-start_time)\n",
    "    \n",
    "    # 输出图像到显示屏\n",
    "    outframe[:] = img_hdmi\n",
    "    hdmi_out.writeframe(outframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
